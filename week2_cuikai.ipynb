{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking1：ALS都有哪些应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS是数学上针对损失函数变量不唯一情况的优化方法（类似于多元函数求最值中分别对每个变量求偏导数），可以解决最优化问题（损失函数最小化）,可以做推荐系统,比如电影推荐,商品推荐,广告推荐等."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking2：ALS进行矩阵分解的时候，为什么可以并行化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从更新公式可以看到，当固定后，迭代更新每个只依赖自己，不依赖与其他的标的物的特征向量，所以可以将不同的更新放到不同的服务器上执行。同理，当固定后，迭代更新时，每个只依赖自己，不依赖与其他用户的特征向量，一样可以将不同用户的更新公式放到不同的服务器上执行。Spark 的ALS算法就是采用这样的方式做到并行化的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking3：梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 批量梯度下降（BGD):\n",
    "1. 每次更新的时候是全样本\n",
    "2. 稳定，收敛慢\n",
    "- 随机梯度下降（SGD)\n",
    "1. 每次更新的时候用 1 个样本，用一个样本来近似所有样本\n",
    "2. 更快收敛，最终解在全局最优解附近，容易陷入局部最优解\n",
    "- 小批量梯度下降\n",
    "1. 每次更新时用 b 个样本，折中的方法\n",
    "2. 速度较快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking4：使用TPOT等AutoML工具，有怎样的好处和不足"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 优点：可以解决特征选择，模型选择，一般可以跑出多种模型的精确度上限\n",
    "- 缺点：不包括数据清洗，大规模数据集非常缓慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinking5：你阅读过和推荐系统/计算广告/预测相关的论文么？有哪些论文是你比较推荐的，可以分享到微信群中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "阅读过，希望以后加大阅读量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action1：对MovieLens数据集进行评分预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlopeOne 算法简单原理：\n",
    "1. 计算 item 之间的评分差的均值，记为评分偏差（两个 item 都评分过的用户）\n",
    "2. 根据 item 间的评分偏差和用户的历史评分，预测用户未来评分的 item 的评分\n",
    "3. 将预测评分排序，取 Top-N 对应的 item 推荐给用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.32   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Reader\n",
    "from surprise import BaselineOnly, KNNBasic, KNNBaseline, SlopeOne\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "import pandas as pd\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# 读取物品（电影）名称信息\n",
    "def read_item_names():\n",
    "    file_name = ('F:\\\\Jupyter_notebook_workdir\\\\BI\\\\week2\\\\MovieLens\\\\movies.csv') \n",
    "    data = pd.read_csv('F:\\\\Jupyter_notebook_workdir\\\\BI\\\\week2\\\\MovieLens\\\\movies.csv')\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    for i in range(len(data['movieId'])):\n",
    "        rid_to_name[data['movieId'][i]] = data['title'][i]\n",
    "        name_to_rid[data['title'][i]] = data['movieId'][i]\n",
    "\n",
    "    return rid_to_name, name_to_rid \n",
    "\n",
    "# 数据读取\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('F:\\\\Jupyter_notebook_workdir\\\\BI\\\\week2\\\\MovieLens\\\\ratings.csv', reader=reader)\n",
    "train_set = data.build_full_trainset()\n",
    "\n",
    "\n",
    "# 使用SlopeOne算法\n",
    "algo = SlopeOne()\n",
    "algo.fit(train_set)\n",
    "# 对指定用户和商品进行评分预测\n",
    "uid = str(196) \n",
    "iid = str(302) \n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action2：Paper Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 见附件 pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action3 Titanic预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法一 : 使用 TPOT 进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "------------------------------\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "------------------------------\n",
      "                            Name   Sex    Ticket        Cabin Embarked\n",
      "count                        891   891       891          204      889\n",
      "unique                       891     2       681          147        3\n",
      "top     Lobb, Mr. William Arthur  male  CA. 2343  C23 C25 C27        S\n",
      "freq                           1   577         7            4      644\n",
      "------------------------------\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "------------------------------\n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "['Age', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Fare', 'Parch', 'Pclass', 'Sex=female', 'Sex=male', 'SibSp']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757ec2eb0a7f47328d6bd3c2bdcf248e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=10100.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8316866486723997\n",
      "Generation 2 - Current best internal CV score: 0.8316866486723997\n",
      "Generation 3 - Current best internal CV score: 0.8372920720607621\n",
      "Generation 4 - Current best internal CV score: 0.8384031134266525\n",
      "Generation 5 - Current best internal CV score: 0.8384031134266525\n",
      "Generation 6 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 7 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 8 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 9 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 10 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 11 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 12 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 13 - Current best internal CV score: 0.8440210909547424\n",
      "Generation 14 - Current best internal CV score: 0.848521750047078\n",
      "Generation 15 - Current best internal CV score: 0.848521750047078\n",
      "Generation 16 - Current best internal CV score: 0.848521750047078\n",
      "Generation 17 - Current best internal CV score: 0.848521750047078\n",
      "Generation 18 - Current best internal CV score: 0.848521750047078\n",
      "Generation 19 - Current best internal CV score: 0.848521750047078\n",
      "Generation 20 - Current best internal CV score: 0.848521750047078\n",
      "Generation 21 - Current best internal CV score: 0.848521750047078\n",
      "Generation 22 - Current best internal CV score: 0.848521750047078\n",
      "Generation 23 - Current best internal CV score: 0.848521750047078\n",
      "Generation 24 - Current best internal CV score: 0.848521750047078\n",
      "Generation 25 - Current best internal CV score: 0.848521750047078\n",
      "Generation 26 - Current best internal CV score: 0.848521750047078\n",
      "Generation 27 - Current best internal CV score: 0.848521750047078\n",
      "Generation 28 - Current best internal CV score: 0.848521750047078\n",
      "Generation 29 - Current best internal CV score: 0.848521750047078\n",
      "Generation 30 - Current best internal CV score: 0.848521750047078\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: XGBClassifier(XGBClassifier(input_matrix, learning_rate=0.1, max_depth=4, min_child_weight=4, n_estimators=100, nthread=1, subsample=0.55), learning_rate=0.001, max_depth=5, min_child_weight=2, n_estimators=100, nthread=1, subsample=0.4)\n",
      "0.8923766816143498\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 数据加载\n",
    "train_data = pd.read_csv('F:/Jupyter_notebook_workdir/BI/week2/Titanic数据集/train.csv')\n",
    "test_data = pd.read_csv('F:/Jupyter_notebook_workdir/BI/week2/Titanic数据集/test.csv')\n",
    "# 数据探索\n",
    "print(train_data.info())\n",
    "print('-'*30)\n",
    "print(train_data.describe())\n",
    "print('-'*30)\n",
    "print(train_data.describe(include=['O']))\n",
    "print('-'*30)\n",
    "print(train_data.head())\n",
    "print('-'*30)\n",
    "print(train_data.tail())\n",
    "# 数据清洗\n",
    "# 使用平均年龄来填充年龄中的 nan 值\n",
    "train_data['Age'].fillna(train_data['Age'].mean(), inplace=True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(),inplace=True)\n",
    "# 使用票价的均值填充票价中的 nan 值\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(), inplace=True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace=True)\n",
    "print(train_data['Embarked'].value_counts())\n",
    "\n",
    "# 使用登录最多的港口来填充登录港口的 nan 值\n",
    "train_data['Embarked'].fillna('S', inplace=True)\n",
    "test_data['Embarked'].fillna('S',inplace=True)\n",
    "\n",
    "# 特征选择\n",
    "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived']\n",
    "test_features = test_data[features]\n",
    "\n",
    "dvec=DictVectorizer(sparse=False)\n",
    "train_features=dvec.fit_transform(train_features.to_dict(orient='record'))\n",
    "print(dvec.feature_names_)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features,\n",
    "   train_labels, train_size=0.75, test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(generations=100, population_size=0, verbosity=2)\n",
    "tpot.fit(train_features,train_labels)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法二 ：使用自定义的 ID3 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载\n",
    "train_data = pd.read_csv('F:/Jupyter_notebook_workdir/BI/week2/Titanic数据集/train.csv')\n",
    "test_data = pd.read_csv('F:/Jupyter_notebook_workdir/BI/week2/Titanic数据集/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "                            Name   Sex    Ticket        Cabin Embarked\n",
      "count                        891   891       891          204      889\n",
      "unique                       891     2       681          147        3\n",
      "top     Lobb, Mr. William Arthur  male  CA. 2343  C23 C25 C27        S\n",
      "freq                           1   577         7            4      644\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "     PassengerId  Survived  Pclass                                      Name  \\\n",
      "886          887         0       2                     Montvila, Rev. Juozas   \n",
      "887          888         1       1              Graham, Miss. Margaret Edith   \n",
      "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889          890         1       1                     Behr, Mr. Karl Howell   \n",
      "890          891         0       3                       Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
      "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
      "887  female  19.0      0      0      112053  30.00   B42        S  \n",
      "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
      "889    male  26.0      0      0      111369  30.00  C148        C  \n",
      "890    male  32.0      0      0      370376   7.75   NaN        Q  \n"
     ]
    }
   ],
   "source": [
    "# 数据探索\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n",
    "# 查看下离散数据的分布\n",
    "print(train_data.describe(include = ['O']))\n",
    "print(train_data.head())\n",
    "print(train_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "     Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
      "0         3    male  22.000000      1      0   7.2500        S\n",
      "1         1  female  38.000000      1      0  71.2833        C\n",
      "2         3  female  26.000000      0      0   7.9250        S\n",
      "3         1  female  35.000000      1      0  53.1000        S\n",
      "4         3    male  35.000000      0      0   8.0500        S\n",
      "..      ...     ...        ...    ...    ...      ...      ...\n",
      "886       2    male  27.000000      0      0  13.0000        S\n",
      "887       1  female  19.000000      0      0  30.0000        S\n",
      "888       3  female  29.699118      1      2  23.4500        S\n",
      "889       1    male  26.000000      0      0  30.0000        C\n",
      "890       3    male  32.000000      0      0   7.7500        Q\n",
      "\n",
      "[891 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 数据清洗\n",
    "train_data['Age'].fillna(train_data['Age'].mean(),inplace = True)\n",
    "test_data['Age'].fillna(test_data['Age'].mean(),inplace = True)\n",
    "\n",
    "train_data['Fare'].fillna(train_data['Fare'].mean(),inplace = True)\n",
    "test_data['Fare'].fillna(test_data['Fare'].mean(),inplace = True)\n",
    "\n",
    "print(train_data['Embarked'].value_counts())\n",
    "train_data['Embarked'].fillna('S',inplace = True)\n",
    "test_data['Embarked'].fillna('S',inplace = True)\n",
    "\n",
    "# 特征选择\n",
    "features = ['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['Survived']\n",
    "test_features = test_data[features]\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Fare', 'Parch', 'Pclass', 'Sex=female', 'Sex=male', 'SibSp']\n"
     ]
    }
   ],
   "source": [
    "# 将字符串类型转化为数字类型\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "train_features = dvec.fit_transform(train_features.to_dict(orient = 'record'))\n",
    "test_features = dvec.fit_transform(test_features.to_dict(orient = 'record'))\n",
    "print(dvec.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [38.        ,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [26.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [29.69911765,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [26.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [32.        ,  0.        ,  1.        , ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造 ID3 决策树\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf.fit(train_features,train_labels)\n",
    "pred_labels = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score准确率为  0.9820\n"
     ]
    }
   ],
   "source": [
    "# 得到 决策树的基于训练集准确率\n",
    "acc_decision_tree = round(clf.score(train_features,train_labels),6)\n",
    "print(u'score准确率为 % .4lf'%acc_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_vaL_score准确率为：0.7842\n"
     ]
    }
   ],
   "source": [
    "# 使用  K 折交叉验证，统计决策树准确率\n",
    "print(u'cross_vaL_score准确率为：%.4lf'%np.mean(cross_val_score(clf,train_features,train_labels,cv = 120)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
